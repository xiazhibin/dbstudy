# coding=utf-8

'''
我们在谈论unicode的时候，在谈论什么

1.ASCII

我们知道，在计算机内部，所有的信息最终都表示为一个二进制。每一个二进制位（bit）有0和1两种状态，
因此八个二进制位就可以组合出256种状态，这被称为一个字节（byte）。
也就是说，一个字节一共可以用来表示256种不同的状态，每一个状态对应一个符号，就是256个符号，从0000000到11111111。

上个世纪60年代，美国制定了一套字符编码，对英语字符与二进制位之间的关系（划重点），做了统一规定。这被称为ASCII码，一直沿用至今。
ASCII码一共规定了128个字符的编码，只占用了一个字节的后面7位，最前面的1位统一规定为0。

0000 0000 0 NUL(null)
01000001 65 A
01100001 97 a
............


2.非ASCII
例如 'é'， 'ג'，还有汉字，光汉字就有10w+，那么多。
一个字节8位，共256个状态，不够分。那么怎么办呢

弄多个字节是，双字节，16位，共256*256=65536个状态
不够？再来一个字节，三字节，256*256*256=16777216(1千万了)



3.Unicode
虽然三字节已经足够表示全地球所有符号，但是
中国，00000000 00000000 00000001 代表 刘
法国，00000000 00000000 00000001 代表 志
日本，00000000 00000000 00000001 代表 恒

世界上存在着多种编码方式，同一个二进制数字可以被解释成不同的符号。
因此，要想打开一个文本文件，就必须知道它的编码方式（划重点，二进制跟符号的对应关系），
否则用错误的编码方式解读，就会出现乱码。
name如果有一种编码，将世界上所有的符号都纳入其中。
每一个符号都给予一个独一无二的编码，那么乱码问题就会消失。
这就是Unicode，就像它的名字都表示的，这是一种所有符号的编码

4. Unicode的问题
Unicode只是一个符号集(字符集)，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储。
比如，汉字"志"的unicode是十六进制数0x5FD7 ，转换成二进制数有15位（101111111010111）(十进制 24535)，
也就是说这个符号的表示至少需要2个字节。表示其他更大的符号，可能需要3个字节或者4个字节，甚至更多。
那么问题来了：
第一个问题是，如何才能区别Unicode和ASCII？计算机怎么知道三个字节表示一个符号，而不是分别表示三个符号呢？
第二个问题是，我们已经知道，英文字母只用一个字节表示就够了，如果Unicode统一规定，
每个符号用三个或四个字节表示，那么每个英文字母前都必然有二到三个字节是0，这对于存储来说是极大的浪费，文本文件的大小会因此大出二三倍，这是无法接受的。

它们造成的结果是：
1）出现了Unicode的多种存储方式，也就是说有许多种不同的二进制格式，可以用来表示Unicode。
2）Unicode在很长一段时间内无法推广，直到互联网的出现




4.UTF-8
UTF-8就是在互联网上使用最广的一种Unicode的实现方式(编码方式)。
UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。

UTF-8的编码规则很简单，只有二条：
1）对于单字节的符号，字节的第一位设为0，后面7位为这个符号的unicode码。因此对于英语字母，UTF-8编码和ASCII码是相同的。
2）对于n字节的符号（n>1），第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的unicode码。

下表总结了编码规则，字母x表示可用编码的位。
Unicode符号范围      | UTF-8编码方式
(十六进制)           | （二进制）
--------------------+---------------------------------------------
0000 0000-0000 007F | 0xxxxxxx
0000 0080-0000 07FF | 110xxxxx 10xxxxxx
0000 0800-0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx
0001 0000-0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx

已知"志"的unicode是5FD7，根据上表，可以发现5FD7处在第三行的范围内（0000 0800-0000 FFFF），
因此"志"的UTF-8编码需要三个字节，即格式是"1110xxxx 10xxxxxx 10xxxxxx"。
然后，从"志"的最后一个二进制位开始，依次从后向前填入格式中的x，多出的位补0。
这样就得到了，
"志"的UTF-8编码是"11100101 10111111 10010111"，转换成十六进制就是0x72dfcb。


以上都是处理 字符和字节 之间的映射关系（划重点）

python2.x 中的str和unicode

对Unicode支持基本正确，但有少数致命缺点的语言。这一类语言比较“现代”，且能理解Unicode，
但依然无法让开发者正确的处理unicode，导致在这些语言中对unicode会出现一些严重不足。
Python 2.x就属于这一类
因为我们经常可以看到这个报错
UnicodeDecodeError: 'ascii'codec can't decode byte 0xe9 in position 2: ordinal not in range(128)

python 类型 str -- 所谓的字符类型 但是实际上是一个字节类型

s0 = 'z'
s1 = '志'

m = 'A'
print type(m)
print len(m)
for i in m:
    print ord(i), bin(ord(i)), hex(ord(i))

print '-----------'
m = '志'
print type(m)
print len(m)
for i in m:
    print ord(i), bin(ord(i)), hex(ord(i))

print '---------'

m = u'志'
print type(m)
print len(m)
for i in m:
    print ord(i), bin(ord(i)), hex(ord(i))

print '---------'

m = u'志'.encode('gbk')
print type(m)
print len(m)
for i in m:
    print ord(i), bin(ord(i)), hex(ord(i))
print '--------'

from urllib import quote
data = '志'
print quote(data)

print '---------'
m = ['你好', '刘志恒', '是', '???']
print m
print 'listnine list: %s' % str(m).decode('string_escape')

print '-------------'
f = '\u5218\u5fd7\u6052'
print f
print(f.decode('unicode-escape'))

byteArr.decode('utf-8') = str
str.encode('utf-8') = byteArr
'''
